# Neuroscience R&D Assistant - Complete Documentation Index

Welcome! This document serves as a master index to help you navigate the entire Neuroscience R&D Assistant project.

## üìã Quick Navigation

### For First-Time Users
1. Start here: [QUICKSTART.md](QUICKSTART.md) - 5-minute setup and basic usage
2. Run examples: `python workflows.py`
3. Check examples in [QUICKSTART.md](QUICKSTART.md#example-research-workflow)

### For Detailed Information
1. Overview: [README.md](README.md) - Complete feature documentation
2. Architecture: [ARCHITECTURE.md](ARCHITECTURE.md) - System design and data flows
3. API Docs: [API_REFERENCE.md](API_REFERENCE.md) - Detailed function documentation

### For Developers
1. Architecture: [ARCHITECTURE.md](ARCHITECTURE.md) - Understand the system design
2. Source Code: [main.py](main.py), [llm_integration.py](llm_integration.py), etc.
3. Extending: See "Extensibility Points" in [ARCHITECTURE.md](ARCHITECTURE.md)

---

## üìÅ File Organization

### Core Python Modules (Production Code)

| File | Purpose | Lines | Key Classes |
|------|---------|-------|------------|
| [main.py](main.py) | Core analysis engine | 450+ | `NeuroscienceRnDAssistant`, `AnalysisTools`, `DataHandler` |
| [llm_integration.py](llm_integration.py) | LLM communication | 500+ | `GPTAdapter`, `NeuroscienceRnDClient`, `PromptBuilder` |
| [visualization.py](visualization.py) | Visualization utilities | 400+ | `NeuroscienceVisualizations`, `AnalysisVisualizer` |
| [workflows.py](workflows.py) | Example workflows | 600+ | Example research pipelines |

### Documentation Files

| File | Purpose | Best For |
|------|---------|----------|
| [README.md](README.md) | Complete guide | Overview of features, usage examples, best practices |
| [QUICKSTART.md](QUICKSTART.md) | Getting started | Fast setup, common tasks, troubleshooting |
| [ARCHITECTURE.md](ARCHITECTURE.md) | System design | Understanding the code structure, extending the system |
| [API_REFERENCE.md](API_REFERENCE.md) | Function documentation | Detailed API specs, parameters, return values |
| [PROJECT_SUMMARY.md](PROJECT_SUMMARY.md) | Project overview | What's included, statistics, capabilities |
| [INDEX.md](INDEX.md) | This file | Navigation and file organization |

### Configuration & Setup Files

| File | Purpose | Action |
|------|---------|--------|
| [requirements.txt](requirements.txt) | Python dependencies | `pip install -r requirements.txt` |
| [.env.template](.env.template) | Environment variables | Copy to `.env` and fill in values |
| [config_template.py](config_template.py) | Configuration settings | Copy to `config.py` for custom settings |
| [.gitignore](.gitignore) | Git configuration | Prevents committing secrets, data, caches |

---

## üéØ What Can You Do?

### Immediate Capabilities

```python
# 1. Create and manage experiments
assistant = NeuroscienceRnDAssistant()
exp = assistant.create_experiment(...)

# 2. Analyze neural data
firing_rates = AnalysisTools.compute_firing_rate(spike_times)
metrics = AnalysisTools.compute_raster_metrics(spike_matrix)

# 3. Get LLM assistance
client = NeuroscienceRnDClient(GPTAdapter())
design = client.design_experiment(...)
hypotheses = client.generate_hypotheses(...)

# 4. Prepare visualizations
viz = NeuroscienceVisualizations()
raster = viz.spike_raster_data(spike_times)
```

See [QUICKSTART.md](QUICKSTART.md#common-tasks) for more examples.

### Research Support

1. **Experimental Design**
   - Get AI suggestions for optimal experimental protocols
   - Compute sample sizes with proper statistical power
   - Review methodology before execution
   - [See example in workflows.py](workflows.py#L28)

2. **Data Analysis**
   - Compute firing rates, cross-correlations, population metrics
   - Get LLM interpretation of results
   - Understand findings in neuroscience context
   - [See example in workflows.py](workflows.py#L73)

3. **Hypothesis Generation**
   - Generate testable hypotheses from observations
   - Get mechanistic explanations for data
   - Plan follow-up experiments
   - [See example in workflows.py](workflows.py#L118)

4. **Literature & Knowledge**
   - Synthesize research topics with LLM
   - Build domain knowledge base
   - Review methodology
   - Get publication guidance

---

## üöÄ Getting Started

### Step 1: Setup (2 minutes)
```bash
# Install dependencies
pip install -r requirements.txt

# Set API key
export OPENAI_API_KEY="sk-..."
```

### Step 2: Run Examples (1 minute)
```bash
python workflows.py
```

### Step 3: Read Documentation (10 minutes)
- Start: [QUICKSTART.md](QUICKSTART.md)
- Explore: [workflows.py](workflows.py)
- Reference: [API_REFERENCE.md](API_REFERENCE.md)

### Step 4: Try Your Data (30 minutes)
```python
from main import DataHandler, AnalysisTools

data, metadata = DataHandler.load_timeseries("your_data.csv")
metrics = AnalysisTools.compute_raster_metrics(data)
```

See [README.md#Quick Start](README.md#quick-start) for complete example.

---

## üìö Documentation by Topic

### Core Concepts
- **Experiments**: [README.md#Experiment Management](README.md), [API_REFERENCE.md#NeuroscienceRnDAssistant](API_REFERENCE.md)
- **Analysis**: [API_REFERENCE.md#AnalysisTools](API_REFERENCE.md), [workflows.py](workflows.py)
- **LLM Integration**: [llm_integration.py](llm_integration.py), [API_REFERENCE.md#LLM Integration](API_REFERENCE.md)
- **Visualization**: [visualization.py](visualization.py), [API_REFERENCE.md#Visualization](API_REFERENCE.md)

### By Research Task
- **Design Experiments**: [QUICKSTART.md#Design an Experiment](QUICKSTART.md), [workflows.py#workflow_experiment_design](workflows.py)
- **Analyze Data**: [QUICKSTART.md#Analyze Spike Data](QUICKSTART.md), [workflows.py#workflow_data_analysis](workflows.py)
- **Generate Hypotheses**: [QUICKSTART.md#Generate Hypotheses](QUICKSTART.md), [workflows.py#workflow_hypothesis_generation](workflows.py)
- **Review Literature**: [API_REFERENCE.md#review_literature](API_REFERENCE.md#review_literature)

### Technical Details
- **Architecture**: [ARCHITECTURE.md](ARCHITECTURE.md)
- **Data Formats**: [README.md#Data Format Support](README.md), [main.py#DataHandler](main.py)
- **Configuration**: [config_template.py](config_template.py), [QUICKSTART.md#Configuration](QUICKSTART.md)
- **LLM Models**: [llm_integration.py#GPTAdapter](llm_integration.py), [README.md#LLM Models Supported](README.md)

---

## üîß Common Tasks

### Load and Analyze Data
```python
from main import DataHandler, AnalysisTools
import numpy as np

# Load data
data, meta = DataHandler.load_timeseries("recording.npz")

# Analyze
metrics = AnalysisTools.compute_raster_metrics(data)
print(f"Mean firing rate: {metrics['mean_firing_rate']:.1f} Hz")
```
See: [QUICKSTART.md#Analyze Spike Data](QUICKSTART.md)

### Design an Experiment
```python
from llm_integration import NeuroscienceRnDClient, GPTAdapter

client = NeuroscienceRnDClient(GPTAdapter())
design = client.design_experiment(
    background="Understanding visual processing",
    objective="Characterize orientation selectivity"
)
print(design)
```
See: [QUICKSTART.md#Design an Experiment](QUICKSTART.md)

### Generate Hypotheses
```python
hypotheses = client.generate_hypotheses(
    background="V1 neurons are direction selective",
    observation="Selectivity decreases with stimulus speed",
    focus="Why does this happen?"
)
```
See: [QUICKSTART.md#Generate Hypotheses](QUICKSTART.md)

### Prepare Visualization Data
```python
from visualization import NeuroscienceVisualizations

viz = NeuroscienceVisualizations()
raster = viz.spike_raster_data(spike_times)
tuning = viz.tuning_curve_data(stimuli, responses)
```
See: [API_REFERENCE.md#Visualization](API_REFERENCE.md)

See [QUICKSTART.md#Common Tasks](QUICKSTART.md) for more examples.

---

## üìñ Learning Path

### Beginner (0-30 minutes)
1. Read: [QUICKSTART.md](QUICKSTART.md) (5 min)
2. Run: `python workflows.py` (5 min)
3. Try: Basic example from [QUICKSTART.md](QUICKSTART.md) (10 min)
4. Explore: One workflow in [workflows.py](workflows.py) (10 min)

### Intermediate (30 minutes - 2 hours)
1. Read: [README.md](README.md) (20 min)
2. Study: [API_REFERENCE.md](API_REFERENCE.md) (30 min)
3. Modify: Example workflows (30 min)
4. Analyze: Your own data (20 min)

### Advanced (2-8 hours)
1. Study: [ARCHITECTURE.md](ARCHITECTURE.md) (60 min)
2. Review: Source code ([main.py](main.py), [llm_integration.py](llm_integration.py)) (90 min)
3. Create: Custom workflow (60 min)
4. Extend: Add new functionality (depends on task)

---

## üõ†Ô∏è Troubleshooting

### Common Issues

| Problem | Solution | Reference |
|---------|----------|-----------|
| "No module named 'openai'" | `pip install openai` | [QUICKSTART.md#Troubleshooting](QUICKSTART.md) |
| "No API key found" | Set OPENAI_API_KEY environment variable | [QUICKSTART.md#Configure OpenAI](QUICKSTART.md) |
| "ModuleNotFoundError" | Run `pip install -r requirements.txt` | [QUICKSTART.md#Install Dependencies](QUICKSTART.md) |
| "MemoryError with large data" | Use HDF5 format, process in chunks | [README.md#Performance Considerations](README.md) |
| "API rate limit exceeded" | Wait before retrying, use gpt-3.5-turbo | [README.md#Troubleshooting](README.md) |

See: [QUICKSTART.md#Troubleshooting](QUICKSTART.md) and [README.md#Troubleshooting](README.md)

---

## üìä Project Statistics

| Metric | Value |
|--------|-------|
| Total Lines of Code | ~2000 |
| Python Modules | 4 |
| Documentation Files | 6 |
| Classes Implemented | 12 |
| Public Methods | 50+ |
| Supported Neuroscience Techniques | 9 |
| Supported Organisms | 6 |
| Brain Regions Documented | 10+ |
| Research Tasks | 7 |
| Data Formats | 3 |

See: [PROJECT_SUMMARY.md#Statistics](PROJECT_SUMMARY.md)

---

## üéì Reference Materials

### Neuroscience Resources
- Techniques: Check [README.md#Supported Neuroscience Techniques](README.md)
- Analysis: See [AnalysisTools documentation](API_REFERENCE.md#AnalysisTools)
- Organisms: See [config_template.py#Supported organisms](config_template.py)

### Python Resources
- NumPy: For numerical computation
- OpenAI Python SDK: For LLM integration
- DataClasses: For structured data

### External Documentation
- OpenAI API: https://platform.openai.com/docs
- NumPy: https://numpy.org/doc/
- Python 3: https://docs.python.org/3/

---

## üîê Security & Best Practices

### Protect Your API Key
- ‚úÖ Store in `.env` file (never commit)
- ‚úÖ Use environment variables
- ‚úÖ Add `.env` to `.gitignore` (already done)
- ‚ùå Never hardcode API key in scripts
- ‚ùå Never commit `.env` file

See: [README.md#Troubleshooting](README.md) and [.gitignore](.gitignore)

### Data Handling
- ‚úÖ Keep raw data separate from processed
- ‚úÖ Document data formats and units
- ‚úÖ Preserve original files for re-analysis
- ‚úÖ Store metadata with data

### Reproducibility
- ‚úÖ Track experiment parameters
- ‚úÖ Version control analysis code
- ‚úÖ Export conversation history
- ‚úÖ Document LLM model versions

---

## ü§ù Contributing & Extending

### How to Extend
1. Add custom analysis: See [ARCHITECTURE.md#Extensibility Points](ARCHITECTURE.md)
2. Add new LLM provider: See [llm_integration.py](llm_integration.py)
3. Create specialized workflows: See [workflows.py](workflows.py)

### Areas for Contribution
- [ ] Additional analysis methods
- [ ] Support for other LLM providers
- [ ] Web UI
- [ ] Database backend
- [ ] Advanced ML methods
- [ ] Unit tests

See: [README.md#Contributing](README.md)

---

## üìù Version Info

- **Project Version**: 1.0.0
- **Created**: February 2026
- **Status**: Production Ready
- **Python**: 3.8+
- **License**: MIT

---

## üÜò Getting Help

1. **Quick questions**: Check [QUICKSTART.md](QUICKSTART.md)
2. **How to use**: See [README.md](README.md) and [QUICKSTART.md](QUICKSTART.md)
3. **API details**: Check [API_REFERENCE.md](API_REFERENCE.md)
4. **System design**: Read [ARCHITECTURE.md](ARCHITECTURE.md)
5. **Examples**: Run [workflows.py](workflows.py)
6. **Docstrings**: Check source code comments

---

## üìû Quick Reference Cheat Sheet

### Setup
```bash
pip install -r requirements.txt
export OPENAI_API_KEY="sk-..."
python workflows.py  # Test
```

### Create Experiment
```python
assistant = NeuroscienceRnDAssistant()
exp = assistant.create_experiment(
    experiment_id="EXP_001", title="...", 
    organism="Mus musculus", ...
)
```

### Analyze Data
```python
from main import AnalysisTools
firing_rates = AnalysisTools.compute_firing_rate(spike_times)
metrics = AnalysisTools.compute_raster_metrics(spike_matrix)
```

### Use LLM
```python
from llm_integration import NeuroscienceRnDClient, GPTAdapter
client = NeuroscienceRnDClient(GPTAdapter())
client.analyze_data(context, data, question)
client.design_experiment(background, objective)
client.generate_hypotheses(background, observation)
```

### Visualizations
```python
from visualization import NeuroscienceVisualizations
viz = NeuroscienceVisualizations()
raster = viz.spike_raster_data(spike_times)
tuning = viz.tuning_curve_data(stimuli, responses)
```

---

## ‚úÖ Checklist: First Time Setup

- [ ] Read [QUICKSTART.md](QUICKSTART.md)
- [ ] Run `pip install -r requirements.txt`
- [ ] Create `.env` file with OpenAI key
- [ ] Run `python workflows.py`
- [ ] Try example from [QUICKSTART.md](QUICKSTART.md)
- [ ] Read [README.md](README.md) for overview
- [ ] Check [API_REFERENCE.md](API_REFERENCE.md) for specific functions
- [ ] Review [ARCHITECTURE.md](ARCHITECTURE.md) for system design

---

## üìå Key Takeaways

1. **Easy Setup**: Install, set API key, run examples (5 minutes)
2. **Powerful**: Analyze data, design experiments, generate hypotheses
3. **Well-Documented**: 6 documentation files covering every aspect
4. **Extensible**: Easy to add custom analysis and new features
5. **Research-Ready**: Built with scientific rigor and best practices
6. **Neuroscience-Focused**: Specialized tools for neuroscience research

---

**Start here**: [QUICKSTART.md](QUICKSTART.md)

**Questions?** Check the documentation files or review the source code docstrings.

**Ready to use?** Follow the [Getting Started](#getting-started) section above.

Happy researching! üß†üî¨

---

**Last Updated**: February 2026
**Index Version**: 1.0
